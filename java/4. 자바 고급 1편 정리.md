# 멀티스레드와 동시성

## 1. 프로세스와 스레드

### 멀티태스킹과 멀티프로세싱

#### 단일 프로그램 실행

연산을 처리할 수 있는 CPU 코어가 1개만 있다고 가정 했을때, 초창기 컴퓨터는 한 번에 하나의 프로그램만 실행했다.  
예를들어, 음악을 들으며 워드 프로그램을 실행하고 싶지만 음악 프로그램이 끝나야 워드 프로그램 실행이 가능했다.  
이를 해결하기 위해 하나의 CPU 코어로 여러 프로그램을 동시에 실행하는 '멀티태스킹' 기술이 등장했다.

#### 멀티태스킹

현대의 CPU 는 초당 수십억 번 이상의 연산을 수행한다.
만약 CPU가 매우 빠르게 두 프로그램의 코드를 번갈아 수행한다면, 사람이 느낄 때 두 프로그램이 동시에 실행되는 것
처럼 느껴질 것이다. (대략 0.01초(10ms) 단위로 돌아가며 실행한다.)  
A 프로그램 0.01초 수행 -> B 프로그램 0.01초 수행 -> A프로그램 0.01초 수행  
사용자는 두 프로그램이 동시 실행 되는 것 같이 느낀다.  
이렇게 각 프로그램의 **실행 시간을 분할해서 마치 동시에 실행되는 것 처럼 하는 기법을 시분할(Time Sharing, 시간
공유) 기법**이라 한다.

> CPU에 어떤 프로그램이 얼마만큼 실행될지는 운영체제가 결정하는데 이것을 스케줄링(Scheduling)이라
> 한다. 이때 단순히 시간으로만 작업을 분할하지는 않고, CPU를 최대한 활용할 수 있는 다양한 우선순위와 최적화
> 기법을 사용한다.

#### 멀티프로세싱

컴퓨터 시스템에서 둘 이상의 프로세서(CPU 코어)를 사용하여 여러 작업을 동시
에 처리하는 기술을 의미한다. 멀티프로세싱 시스템은 하나의 CPU 코어만을 사용하는 시스템보다 동시에 더 많은 작업
을 처리할 수 있다.

#### 멀티프로세싱 vs. 멀티태스킹

멀티프로세싱은 하드웨어 장비의 관점이고, 멀티태스킹은 운영체제 소프트웨어의 관점이다.

- **멀티프로세싱**
  - **여러 CPU(여러 CPU 코어)를 사용**하여 동시에 여러 작업을 수행하는 것을 의미한다.
  - 하드웨어 기반으로 성능을 향상시킨다.
  - 예: 다중 코어 프로세서를 사용하는 현대 컴퓨터 시스템
- **멀티태스킹**
  - 단일 CPU(단일 CPU 코어)가 여러 작업을 동시에 수행하는 것처럼 보이게 하는 것을 의미한다.
  - 소프트웨어 기반으로 **CPU 시간을 분할하여 각 작업에 할당**한다.
  - 예: 현대 운영 체제에서 여러 애플리케이션이 동시에 실행되는 환경

---

### 프로세스와 스레드

- **프로세스**

  - 실행중인 프로그램
  - 각 프로세스는 독립적인 메모리 공간을 갖고 있으며, 운영체제에서 별도의 작업 단위로 분리해서 관리된다.
  - 하나의 프로세스가 충돌해도 다른 프로세스에는 영향을 미치지 않는다.

- **스레드**

  - 프로세스는 하나 이상의 스레드를 반드시 포함한다.
  - 스레드는 프로세스 내에서 실행되는 작업의 단위이다.
  - 한 프로세스 내에서 여러 스레드가 존재할 수 있으며, 이들은 **프로세스가 제공하는 동일한 메모리 공간을 공유**한다.
  - 스레드는 프로세스보다 단순하므로 생성 및 관리가 단순하고 가볍다.

- **단일 스레드**: 한 프로세스 내에 하나의 스레드만 존재
- **멀티 스레드**: 한 프로세스 내에 여러 스레드가 존재

#### 멀티스레드가 필요한 이유

- 워드 프로그램으로 문서를 편집하면서, 문서가 자동으로 저장되고, 맞춤법 검사도 함께 수행된다.
- 유튜브는 영상을 보는 동안, 댓글도 달 수 있다.

---

### 컨텍스트 스위칭

CPU 코어가 하나일 때 멀티태스킹은 여러 스레드를 번갈아가며 실행하는 방식으로 동작한다. 운영체제는 스레드를 잠시 멈출 때 현재 실행 상태(레지스터, 변수 값 등)를 메모리에 저장하고, 다른 스레드 실행 후 다시 불러온다.  
이렇게 문맥을 저장하고 복원하는 과정을 **컨텍스트 스위칭**이라 한다. 이 과정은 CPU 입장에서 추가 작업이 필요하기 때문에 성능 오버헤드가 발생한다.

#### CPU-Bound 작업

- CPU 계산이 많은 작업 (예: 수학 연산, 영상 인코딩 등)
- CPU가 작업 속도를 결정
- 스레드 수 = CPU 코어 수 + 1 정도가 적절

#### I/O-Bound 작업

- DB, 파일, 네트워크 등 외부 I/O가 많은 작업
- CPU는 대부분 대기 (I/O가 끝날 때까지)
- 스레드 수 = CPU 코어 수보다 훨씬 많이 생성 가능
  - CPU를 충분히 활용할 수 있는 수준까지 스레드 늘림
  - 단, 스레드가 너무 많으면 컨텍스트 스위칭 비용 발생 → 적절한 성능 테스트 필요

#### 웹 서버 실무에서의 특징

- 대부분 I/O-Bound 작업 (DB 조회, 네트워크 통신 등)
- 요청 1개당 스레드 1개 사용
- CPU를 거의 사용하지 않으므로 코어 수보다 많은 스레드를 둬도 됨
- 무조건 좋은 서버를 쓰는 것보다 스레드 수 조정이 더 효과적

---

## 2. 스레드 생성과 실행

### 스레드 생성

#### 1. Thread 상속

```java
public class HelloThreadMain {

    public static void main(String[] args) {
        System.out.println(Thread.currentThread().getName() + ": main() start");

        HelloThread helloThread = new HelloThread();
        System.out.println(Thread.currentThread().getName() + ": start() 호출 전");
        helloThread.start();
        System.out.println(Thread.currentThread().getName() + ": start() 호출 후");

        System.out.println(Thread.currentThread().getName() + ": main() end");
    }

    static class HelloThread extends Thread {

        @Override
        public void run() {
            System.out.println(Thread.currentThread().getName() + ": run()");
        }
    }
}
```

#### 2. Runnable interface 구현

```java
public class HelloRunnableMain {

    public static void main(String[] args) {
        System.out.println(Thread.currentThread().getName() + ": main() start");

        HelloRunnable runnable = new HelloRunnable();
        Thread thread = new Thread(runnable);
        thread.start();

        System.out.println(Thread.currentThread().getName() + ": main() end");
    }

    static class HelloRunnable implements Runnable {

        @Override
        public void run() {
            System.out.println(Thread.currentThread().getName() + ": run()");
        }
    }
}
```

---

### start() vs run()

스레드의 `start()` 대신에 재정의한 `run()` 메서드를 직접 호출하면 어떻게 될까?

> `thread.run` 을 하면 Thread를 생성하는게 아닌, 그냥 해당 객체의 `run()` 메서드를 실행하는 것이다.

---

### 데몬 스레드

스레드는 사용자(user) 스레드와 데몬(daemon) 스레드 2가지 종류로 구분할 수 있다.

**사용자 스레드(non-daemon 스레드)**

- 프로그램의 주요 작업을 수행한다.
- 작업이 완료될 때까지 실행된다.
- 모든 user 스레드가 종료되면 JVM도 종료된다.

**데몬 스레드**

- 백그라운드에서 보조적인 작업을 수행한다.
- 모든 user 스레드가 종료되면 데몬 스레드는 자동으로 종료된다.

JVM은 데몬 스레드의 실행 완료를 기다리지 않고 종료된다. 데몬 스레드가 아닌 모든 스레드가 종료되면, 자바 프로그램도 종료된다.

```java
DaemonThread daemonThread = new DaemonThread();
daemonThread.setDaemon(true); // 데몬 스레드 여부
daemonThread.start();
```

- `setDaemon(true)` : 데몬 스레드로 설정한다.
- 데몬 스레드 여부는 `start()` 실행 전에 결정해야 한다. 이후에는 변경되지 않는다.
- 기본 값은 `false` 이다. (user 스레드가 기본)

### Thread 상속 vs Runnable 구현

**스레드 사용할 때는 `Thread` 를 상속 받는 방법보다 `Runnable` 인터페이스를 구현하는 방식을 사용하자.**

자바는 단일 상속만 가능하므로,`Thread` 를 상속 받으면, 다른 클래스를 상속 받을 수 없다.  
인터페이스 보다 유연성이 떨어진다.

`Runnable` 구현은 스레드와 실행할 작업을 분리하여 코드 가독성이 높고,  
**여러 스레드가 동일한 `Runnable` 객체를 공유할 수 있어** 자원 관리를 효율적으로 할 수 있다.

---

## 3. 스레드 제어와 생명 주기 1

## 스레드 상태

**getState()**: 스레드의 현재 상태를 반환하는 메서드이다. 반환되는 값은 `Thread.State` 열거형에 정의된 상
수 중 하나이다. 주요 상태는 다음과 같다.

- **New (새로운 상태)**: 스레드가 생성되었으나 아직 시작되지 않은 상태.
- **Runnable (실행 가능 상태)**: 스레드가 실행 중이거나 실행될 준비가 된 상태.
- **일시 중지 상태들 (Suspended States)**
  - **Blocked (차단 상태)**: 스레드가 동기화 락을 기다리는 상태.
  - **Waiting (대기 상태)**: 스레드가 무기한으로 다른 스레드의 작업을 기다리는 상태.
  - **Timed Waiting (시간 제한 대기 상태)**: 스레드가 일정 시간 동안 다른 스레드의 작업을 기다리는 상태.
- **Terminated (종료 상태)**: 스레드의 실행이 완료된 상태.

```java
Thread thread = new Thread(new HelloRunnable(), "myThread");
thread.start();
System.out.println(thread.getState());
```

1. **New (새로운 상태)**

- 스레드가 생성되고 아직 시작되지 않은 상태이다.
- 이 상태에서는 `Thread` 객체가 생성되지만, `start()` 메서드가 호출되지 않은 상태이다.
- 예: `Thread thread = new Thread(runnable);

2. **Runnable (실행 가능 상태)**

- 스레드가 실행될 준비가 된 상태이다. 이 상태에서 스레드는 실제로 CPU에서 실행될 수 있다.
- `start()` 메서드가 호출되면 스레드는 이 상태로 들어간다.
- 예: `thread.start();`
- 실행 중이거나 실행 대기 중인 상태 (스케줄러의 실행 대기열에 포함된 상태)
- 운영체제 스케줄러의 실행 대기열에 있든, CPU에서 실제 실행되고 있든 모두 `RUNNABLE` 상태이
  다. 자바에서 둘을 구분해서 확인할 수는 없다.
- 보통 실행 상태라고 부른다.

3. **Blocked (차단 상태)**

- 스레드가 다른 스레드에 의해 동기화 락을 얻기 위해 기다리는 상태이다.
- 예를 들어, `synchronized` 블록에 진입하기 위해 락을 얻어야 하는 경우 이 상태에 들어간다.

4. **Waiting (대기 상태)**

- 스레드가 다른 스레드의 특정 작업이 완료되기를 무기한 기다리는 상태이다.
- `wait()` , `join()` 메서드가 호출될 때 이 상태가 된다.
- 스레드는 다른 스레드가 `notify()` 또는 `notifyAll()` 메서드를 호출하거나, `join()` 이 완료될 때 까지 기다린다.

5. **Timed Waiting (시간 제한 대기 상태)**

- 스레드가 특정 시간 동안 다른 스레드의 작업이 완료되기를 기다리는 상태이다.
- `sleep(long millis)` , `wait(long timeout)` , `join(long millis)` 메서드가 호출될 때 이 상태가 된다.

6. **Terminated (종료 상태)**

- 스레드의 실행이 완료된 상태이다.
- 스레드가 정상적으로 종료되거나, 예외가 발생하여 종료된 경우 이 상태로 들어간다.
- 스레드는 한 번 종료되면 다시 시작할 수 없다.

**자바 스레드의 상태 전이 과정**

1. **New → Runnable**: `start()` 메서드를 호출하면 스레드가 `Runnable` 상태로 전이된다.
2. **Runnable → Blocked/Waiting/Timed Waiting**: 스레드가 락을 얻지 못하거나, `wait()` 또는 `sleep()` 메서드를 호출할 때 해당 상태로 전이된다.
3. **Blocked/Waiting/Timed Waiting → Runnable**: 스레드가 락을 얻거나, 기다림이 완료되면 다시 `Runnable` 상태로 돌아간다.
4. **Runnable → Terminated**: 스레드의 `run()` 메서드가 완료되면 스레드는 `Terminated` 상태가 된다.

---

### 체크 예외 재정의

- **체크 예외**
  - 부모 메서드가 체크 예외를 던지지 않는 경우, 재정의된 자식 메서드도 체크 예외를 던질 수 없다.
  - 자식 메서드는 부모 메서드가 던질 수 있는 체크 예외의 하위 타입만 던질 수 있다.
- **언체크(런타임) 예외**
  - 예외 처리를 강제하지 않으므로 상관없이 던질 수 있다.

`Runnable` 인터페이스의 `run()` 메서드는 아무런 체크 예외를 던지지 않는다.  
따라서 `Runnable` 인터페이스의 `run()` 메서드를 재정의 하는 곳에서는 체크 예외를 밖으로 던질 수 없다.

> 부모 클래스의 메서드를 호출하는 클라이언트 코드는 부모 메서드가 던지는 특정 예외만을 처리하도록 작성된다.  
> 자식 클래스가 더 넓은 범위의 예외를 던지면 해당 코드는 모든 예외를 제대로 처리하지 못할 수 있다.  
> 이는 예외 처리의 일관성을 해치고, 예상하지 못한 런타임 오류를 초래할 수 있다.

```java
class Parent {
    void method() throws InterruptedException {
        // ...
    }
}

class Child extends Parent {
    @Override
    void method() throws Exception {
        // ...
    }
}

public class Test {
    public static void main(String[] args) {
        Parent p = new Child();
        try {
            p.method();
        } catch (InterruptedException e) {
            // InterruptedException 처리
        }
    }
}
```

- 자바 컴파일러는 `Parent p` 의 `method()` 를 호출한 것으로 인지한다.
- `Parent p` 는 `InterruptedException` 를 반환하는데, 그 자식이 전혀 다른 예외를 반환한다면 클라이언트는 해당 예외를 잡을 수 없다. 이것은 확실하게 모든 예외를 체크하는 체크 예외의 규약에 맞지 않는다.
- 따라서 자바에서 체크 예외의 메서드 재정의는 다음과 같은 규칙을 가진다.

**체크 예외 재정의 규칙**

- 자식 클래스에 재정의된 메서드는 부모 메서드가 던질 수 있는 체크 예외의 하위 타입만을 던질 수 있다.
- 원래 메서드가 체크 예외를 던지지 않는 경우, 재정의된 메서드도 체크 예외를 던질 수 없다.

---

## join

- `thread.join` 을 사용하면, 다른 스레드가 종료 될 때 까지 기다린다.
  - `join()`을 호출한 스레드 A는 대상 스레드 B가 자신의 작업을 모두 마치고 종료될 때까지 실행을 멈추고 기다린다.
- `join()`은 대상 스레드가 끝날 때까지 무한히 기다리는 반면, `join(millis)`는 지정된 시간 동안만 기다린다. 시간 초과 시 기다림을 멈추고 다음 코드를 실행한다.

> `this` 는 호출된 인스턴스 메서드가 소속된 객체를 가리키는 참조이며, 이것이 스택 프레임 내부에 저장되어있다.

## 4. 스레드 제어와 생명 주기 2

### 인터럽트

자바 스레드 인터럽트란, 실행 중인 스레드를 강제로 종료하는 것이 아니라, 작업을 멈춰달라고 요청하는 **'협력적인 중단 신호'** 이다.
신호를 받은 스레드가 스스로 현재 작업을 안전하게 마무리하고 종료하도록 유도하는 방식이다.

**인터럽트의 작동 원리**

- 인터럽트는 스레드 내부에 유지되는 '인터럽트 상태(interrupted status)'라는 불리언(`boolean`) 플래그를 통해 작동한다.

1. 인터럽트 요청: 다른 스레드가 특정 스레드의 `thread.interrupt()` 메서드를 호출한다.
2. 상태 변경: `thread.interrupt()` 메서드가 호출된 스레드의 '인터럽트 상태' 플래그가 `true`로 설정된다.
3. 상태 확인 및 처리: 인터럽트 신호를 받은 스레드는 주기적으로 자신의 인터럽트 상태를 확인하고 그에 따른 처리를 수행한다.

- **`Thread.currentThread().isInterrupted()`**

  - 해당 스레드의 '인터럽트 상태'를 반환한다.
  - 상태를 확인만 하고 변경하지는 않는다.

- **`Thread.interrupted()`**
  - 현재 스레드의 '인터럽트 상태'를 반환한 후, **그 상태를 false로 초기화**한다.
  - 정적(static) 메서드이며, 호출하면 인터럽트 상태가 초기화된다는 점에 유의해야 한다.

> #### `InterruptedException` 예외
>
> 만약 스레드가 sleep(), wait(), join()과 같이 일시 정지(waiting) 상태에 있을 때 인터럽트가 걸리면, 즉시 InterruptedException 예외가 발생한다. 이 예외가 발생하면 스레드는 일시 정지 상태에서 즉시 깨어나 catch 블록의 코드를 실행하게 된다.
>
> 중요한 것은 InterruptedException이 발생하면, JVM이 자동으로 해당 스레드의 '인터럽트 상태'를 false로 초기화한다는 점이다.  
> 따라서 catch 블록에서 인터럽트 상태를 보존하고 싶다면, Thread.currentThread().interrupt()를 다시 호출하여 상태를 true로 설정해주어야 한다.

### yield

현재 실행 중인 스레드가 자신에게 할당된 실행 시간(Time Slice)을 자발적으로 반납하여, 스레드 스케줄러가 자신과 동일한 우선순위를 가진 다른 스레드에게 실행 기회를 주도록 **제안(suggest)** 하는 메서드이다.

> "나는 잠시 쉬어도 괜찮으니, 혹시 나와 같은 중요도(우선순위)를 가진 다른 스레드가 대기 중이라면 먼저 실행해"라고 운영체제(스케줄러)에 제안

- 강제성 없음: yield()를 호출해도 스케줄러가 이를 무시하고 해당 스레드를 계속 실행할 수 있다. 즉, 실행을 양보한다는 보장이 없다.
- 동일 우선순위: 자신보다 우선순위가 낮은 스레드에게는 양보하지 않는다.

> `Thread.yield()`는 Runnable 상태를 유지하며 잠깐 CPU 사용 기회를 양보하지만,  
> `Thread.sleep()`은 스레드를 Timed Waiting 상태로 완전히 옮겨 스케줄링에서 제외한다.
>
> - 모든 스레드가 쉬고있는데, `sleep()`을 하면 본인도 쉴 수 있지만, `yield()` 는 본인이라도 실행한다.
>
> Runnable 상태는 Running , Ready 두 상태가 있는데, 자바에선 두 상태를 구별하진 못한다.  
> `yield` Running 상태를 Ready로 바꾸는 것이다.

---

## 5. 메모리 가시성

멀티스레드 환경에서 한 스레드가 변경한 값이 다른 스레드에서 언제 보이는지에 대한 것을 메모리 가시성(memory visibility)이라 한다.  
이름 그대로 메모리에 변경한 값이 보이는가, 보이지 않는가의 문제이다.

```java
public class VolatileCountMain {

    public static void main(String[] args) {
        MyTask task = new MyTask();
        Thread t = new Thread(task, "work");
        t.start();

        sleep(1000);

        task.flag = false;
        log("flag = " + task.flag + ", count = " + task.count + " in main");
    }

    static class MyTask implements Runnable {
        //boolean flag = true;
        //long count;
        volatile boolean flag = true;
        volatile long count;

        @Override
        public void run() {
            while(flag) {
                count++;
                //1억번에 한번씩 출력
                if (count % 100_000_000 == 0) {
                    log("flag = " + flag + ", count = " + count + " in while()");
                }
            }
            log("flag = " + flag + ", count = " + count + " 종료");
        }
    }
}
```

```java
// 1번
boolean flag = true;
long count;

// 2번
volatile boolean flag = true;
volatile long count;
```

위 코드에서 1번 주석으로 코드를 실행하면, main 스레드에서 바꾼 flag값이 즉시 적용 되지 않는다.  
이유는 CPU는 성능을 위해 메인 메모리에 있는 데이터를 CPU 캐시 메모리에 저장하는데, **멀티코어 환경에서는 각 코어마다 별도의 캐시 메모리를 가지기 때문이다.**

이로 인해 다음과 같은 상황이 발생한다.

1.  **값 복사:** `work` 스레드를 실행하는 **CPU 1번 코어**는 `flag` 변수의 값(`true`)을 자신의 캐시 메모리로 복사해 와서 사용한다.
2.  **캐시 사용:** `while(flag)` 문은 성능을 위해 매번 메인 메모리까지 접근하지 않고, **빠른 1번 코어의 캐시에 저장된 `flag` 값**을 계속 읽어 연산을 수행한다.
3.  **다른 코어에서의 변경:** 잠시 후, `main` 스레드를 실행하는 **CPU 2번 코어**가 `flag` 값을 `false`로 변경한다. 이 변경 사항은 **일단 2번 코어의 캐시에 먼저 기록된다.**
4.  **가시성 문제 발생:** 2번 코어 캐시의 변경된 값이 메인 메모리에 즉시 반영된다는 보장이 없으며, 설령 반영되더라도 1번 코어는 이 사실을 모르고 **계속 자신의 캐시에 저장된 `true` 값을 바라보게 된다.** 그 결과 `work` 스레드는 `while`문을 빠져나오지 못하고 무한 루프에 빠지게 된다.

### `volatile` 키워드의 역할

이때 **`volatile` 키워드**를 사용하면 이 가시성 문제를 해결할 수 있다. 변수에 `volatile`을 붙이는 것은 컴파일러와 CPU에게 다음과 같이 약속하는 것과 같다.

- **값을 쓸 때 (Write):** 이 변수에 값을 쓰는 스레드는 CPU 캐시에만 값을 기록하지 말고, **즉시 메인 메모리까지 변경된 값을 전달(flush)해야 한다.**
- **값을 읽을 때 (Read):** 이 변수의 값을 읽는 스레드는 CPU 캐시에 저장된 값이 있더라도 이를 무시하고, **항상 메인 메모리에서 최신 값을 직접 가져와야 한다.**

결론적으로 `volatile`은 여러 스레드에서 공유되는 변수의 변경 사항이 특정 CPU의 캐시에만 머무르지 않고 즉시 메인 메모리에 반영되도록 강제하여, 다른 모든 스레드가 이 최신 값을 바라보도록 보장하는 역할을 한다. 이를 통해 **'메모리 가시성'을 확보하는 것이다.**

---

## 6. 동기화 - synchronized

**임계 영역(critical section)**
임계 영역(Critical Section)이란 여러 스레드가 동시에 접근할 경우, 데이터 불일치나 예상치 못한 동작을 일으킬 수 있는 코드 영역을 말한다.  
보통 여러 스레드가 동시에 수정해서는 안 되는 공유 자원(공유 변수, 공유 객체 등)에 접근하는 부분이 이에 해당한다.

> 여러 스레드가 동시에 공유 자원을 수정하려고 하면 의도한 결과가 나오지 않을 수 있다.  
> 예를 들어, A와 B 스레드가 동시에 `int amount = 1000;` 필드 값을 기준으로 `800`을 출금하려 한다고 가정하자.  
> `if (amount >= 800)` 이라는 조건을 통과해야만 출금이 가능한데, 두 스레드가 거의 동시에 `amount`의 값(1000)을 읽어가면, 두 스레드 모두 조건을 `true`로 판단하여 출금을 진행하게 된다.  
> 이런 문제를 막기 위해, **해당 코드 영역을 임계 영역으로 지정하여 한 번에 하나의 스레드만 실행되도록 보장**해야 한다.

### 임계 영역 지정 방법

```java
// 1. 메서드 전체를 임계 영역으로 지정
public synchronized boolean withdraw(int amount) {
    // ...
}

// 2. 코드의 특정 블록만 임계 영역으로 지정
public void someMethod() {
    // ... 동기화가 필요 없는 코드 ...
    synchronized (this) {
        // ... 동기화가 필요한 코드 ...
    }
}
```

### synchronized 동작 원리

- **모든 객체는 내부에 자신만의 고유한 잠금 장치, 즉 락(Lock)을 하나씩 가지고 있다.**
  - 이를 **모니터 락(Monitor Lock)** 이라고 부른다.
- 스레드가 `synchronized`로 보호된 임계 영역에 진입하기 위해서는, 반드시 해당 코드 블록이 동기화하는 객체의 **락을 획득**해야 한다.
- A 스레드가 락을 획득하여 임계 영역에 진입한 후 작업이 끝나고 락을 **반납**하면, 다른 대기 중인 스레드(B)가 락을 획득할 기회를 얻는다.

다만, `synchronized`는 직관적이지만 다음과 같은 한계점을 가진다.

- 락을 얻기 위해 대기하는 스레드들 중 **어떤 스레드가 다음에 락을 얻을지는 전혀 보장되지 않는다.**
- 이 때문에 운이 나쁘면 **특정 스레드는 락을 얻지 못하고 무한정 대기하는 기아 상태(Starvation)** 에 빠질 수 있다.
- 락을 기다리는 동안 **인터럽트(Interrupt)를 할 수 없으며, 대기 시간을 설정하는 것도 불가능**하다.
- 이렇게 락을 얻기 위해 대기하는 스레드는 **BLOCKED 상태**가 된다.

---

## 7. 고급 동기화 - concurrent.Lock

## LockSupport

**synchronized 단점**

- **무한 대기**: `BLOCKED` 상태의 스레드는 락이 풀릴 때 까지 무한 대기한다.
  - 특정 시간까지만 대기하는 타임아웃X
  - 중간에 인터럽트X
- **공정성**: 락이 돌아왔을 때 `BLOCKED` 상태의 여러 스레드 중에 어떤 스레드가 락을 획득할 지 알 수 없다. 최악의
  경우 특정 스레드가 너무 오랜기간 락을 획득하지 못할 수 있다
  > 이런 문제를 해결하기 위해 자바 1.5부터 `java.util.concurrent` 라는 동시성 문제 해결을 위한 라이브러리 패키지가 추가된다.

### LockSupport 기능

`LockSupport` 는 스레드를 `WAITING` 상태로 변경한다.  
`WAITING` 상태는 누가 깨워주기 전까지는 계속 대기한다. 그리고 CPU 실행 스케줄링에 들어가지 않는다.

- `park()` : 스레드를 `WAITING` 상태로 변경한다.
- `parkNanos(nanos)` : 스레드를 나노초 동안만 `TIMED_WAITING` 상태로 변경한다.
  - 지정한 나노초가 지나면 `TIMED_WAITING` 상태에서 빠져나오고 `RUNNABLE` 상태로 변경된다.
- unpark(thread)`:`WAITING`상태의 대상 스레드를`RUNNABLE` 상태로 변경한다.

> `LockSupport.park();`  
> `LockSupport.unpark(thread1);`  
> `LockSupport.parkNanos(2000_000000); // 2초`

### BLOCKED vs WAITING

**인터럽트**

- `BLOCKED`: **인터럽트가 걸려도 대기 상태를 빠져나오지 못한다.** 여전히 `BLOCKED` 상태이다.
- `WAITING`, `TIMED_WAITING`: 상태는 인터럽트가 걸리면 대기 상태를 빠져나온다. 그래서 `RUNNABLE` 상태로 변한다.

**용도**

- `BLOCKED` 상태는 자바의 `synchronized` 에서 락을 획득하기 위해 대기할 때 사용된다.
- `WAITING` 상태는 다양한 상황에서 사용된다. 예를 들어, `Thread.join()` , `LockSupport.park()` , `Object.wait()` 와 같은 메서드 호출 시 `WAITING` 상태가 된다.

**대기(`WAITING` ) 상태와 시간 대기 상태(`TIMED_WAITING` )는 서로 짝이 있다.**

- `Thread.join()` , `Thread.join(long millis)`
- `LockSupport.park()` , `LockSupport.parkNanos(long nanos)`
- `Object.wait()` , `Object.wait(long timeout)`

> `BLOCKED` 상태는 `synchronized` 에서만 사용하는 특별한 대기 상태라고 이해하면 된다.

> `LockSupport` 는 너무 저수준이다. `synchronized` 처럼 더 고수준의 기능이 필요하다.  
> 자바는 `Lock` 인터페이스와 `ReentrantLock` 이라는 구현체로 이런 기능들을 이미 다 구현해 두었다.  
> `ReentrantLock` 은 `LockSupport` 를 활용해서 `synchronized` 의 단점을 극복하면서도 매우 편리하게 임계 영역을 다룰 수 있는 다양한 기능을 제공한다.

## ReentrantLock - 이론

**Lock 인터페이스**

```java
package java.util.concurrent.locks;
public interface Lock {
    void lock();
    void lockInterruptibly() throws InterruptedException;
    boolean tryLock();
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
    void unlock();
    Condition newCondition();
}
```

**`void lock()`**

- 락을 획득한다. 만약 다른 스레드가 이미 락을 획득했다면, 락이 풀릴 때까지 현재 스레드는 대기(`WAITING` )한다. 이 메서드는 인터럽트에 응답하지 않는다.
- 예) 맛집에 한번 줄을 서면 끝까지 기다린다. 친구가 다른 맛집을 찾았다고 중간에 연락해도 포기하지 않고 기다린다.

> `lock()` 을 호출해서 락을 얻기 위해 대기중인 스레드에 인터럽트가 발생하면 순간 대기 상태를 빠져나오는 것은 맞다.  
> 그래서 아주 짧지만 `WAITING` `RUNNABLE` 이 된다. 그런데 `lock()` 메서드 안에서 해당 스레드를 다시 `WAITING` 상태로 강제로 변경해버린다.  
> 이런 원리로 인터럽트를 무시하는 것이다. 참고로 인터럽트가 필요하면 `lockInterruptibly()` 를 사용하면 된다. 새로운 `Lock` 은 개발자에게 다양한 선택권을 제공한다.

**주의!**  
여기서 사용하는 락은 객체 내부에 있는 모니터 락이 아니다! `Lock` 인터페이스와 `ReentrantLock` 이 제공하는 기능이다!  
모니터 락과 `BLOCKED` 상태는 `synchronized` 에서만 사용된다.

**`void lockInterruptibly()`**

- 락 획득을 시도하되, 다른 스레드가 인터럽트할 수 있도록 한다. 만약 다른 스레드가 이미 락을 획득했다면, 현재 스레드는 락을 획득할 때까지 대기한다. 대기 중에 인터럽트가 발생하면 `InterruptedException` 이 발생하며 락 획득을 포기한다.
- 예) 맛집에 한번 줄을 서서 기다린다. 다만 친구가 다른 맛집을 찾았다고 중간에 연락하면 포기한다.

**`boolean tryLock()`**

- 락 획득을 시도하고, 즉시 성공 여부를 반환한다. 만약 다른 스레드가 이미 락을 획득했다면 `false` 를 반환하고, 그렇지 않으면 락을 획득하고 `true` 를 반환한다.
- 예) 맛집에 대기 줄이 없으면 바로 들어가고, 대기 줄이 있으면 즉시 포기한다.

**`boolean tryLock(long time, TimeUnit unit)`**

- 주어진 시간 동안 락 획득을 시도한다. 주어진 시간 안에 락을 획득하면 `true` 를 반환한다. 주어진 시간이 지나도 락을 획득하지 못한 경우 `false` 를 반환한다. 이 메서드는 대기 중 인터럽트가 발생하면 `InterruptedException` 이 발생하며 락 획득을 포기한다.
- 예) 맛집에 줄을 서지만 특정 시간 만큼만 기다린다. 특정 시간이 지나도 계속 줄을 서야 한다면 포기한다. 친구가 다른 맛집을 찾았다고 중간에 연락해도 포기한다.

**`void unlock()`**

- 락을 해제한다. 락을 해제하면 락 획득을 대기 중인 스레드 중 하나가 락을 획득할 수 있게 된다. 락을 획득한 스레드가 호출해야 하며, 그렇지 않으면 `IllegalMonitorStateException` 이 발생할 수 있다.
- 예) 식당안에 있는 손님이 밥을 먹고 나간다. 식당에 자리가 하나 난다. 기다리는 손님께 이런 사실을 알려주어야 한다. 기다리던 손님중 한 명이 식당에 들어간다.

**`Condition newCondition()`**

- `Condition` 객체를 생성하여 반환한다. `Condition` 객체는 락과 결합되어 사용되며, 스레드가 특정 조건을 기다리거나 신호를 받을 수 있도록 한다. 이는 `Object` 클래스의 `wait` , `notify` , `notifyAll` 메서드와 유사한 역할을 한다.

> `synchronized` 의 단점 2가지, 무한 대기와 공정성 중,  
> 무한 대기는 `Lock` 인터페이스의 다양항 가능으로 해결되었다.  
> 공정성의 경우는 `Lock` 인터페이스의 대표적인 구현체로 `ReentrantLock` 이 있는데,  
> 이 클래스는 스레드가 공정하게 락을 얻을 수 있는 모드를 제공한다.
>
> ```java
> // 비공정 모드 락
> private final Lock nonFairLock = new ReentrantLock();
> // 공정 모드 락
> private final Lock fairLock = new ReentrantLock(true);
> ```

### 비공정 모드 (Non-fair mode)

- **성능 우선**: 락을 획득하는 속도가 빠르다.
- **선점 가능**: 새로운 스레드가 기존 대기 스레드보다 먼저 락을 획득할 수 있다.
- **기아 현상 가능성**: 특정 스레드가 계속해서 락을 획득하지 못할 수 있다.

### 공정 모드 (Fair mode)

- **공정성 보장**: 대기 큐에서 먼저 대기한 스레드가 락을 먼저 획득한다.
- **기아 현상 방지**: 모든 스레드가 언젠가 락을 획득할 수 있게 보장된다.
- **성능 저하**: 락을 획득하는 속도가 느려질 수 있다.

> **비공정 모드**는 성능을 중시하고, 스레드가 락을 빨리 획득할 수 있지만, 특정 스레드가 계속해서 락을 획득하지 못 할 수 있다.  
> **공정 모드**는 스레드가 락을 획득하는 순서를 보장하여 공정성을 중시하지만, 성능이 저하될 수 있다.

---

## 8. 생산자 소비자 문제1

### 1. 생산자-소비자 문제의 본질

생산자-소비자 문제란, 여러 스레드가 하나의 자원(버퍼)을 공유하며 발생하는 대표적인 동시성 문제이다.

- **생산자(Producer)**: 데이터를 생성하여 공유 버퍼에 추가하는 역할을 한다.
- **소비자(Consumer)**: 공유 버퍼에서 데이터를 가져가 사용하는 역할을 한다.
- **버퍼(Buffer)**: 생산된 데이터가 임시로 저장되는 크기가 한정된 공간이다.

이 구조에서 핵심적인 충돌은 버퍼의 상태에 따라 발생한다. 버퍼가 가득 차면 생산자는 더는 데이터를 넣을 수 없어 대기해야 하고, 버퍼가 비어 있으면 소비자는 가져갈 데이터가 없어 대기해야 한다.

### 2. 문제 해결을 위한 단계적 접근과 실패, 그리고 해결

##### **1단계 (V1-BoundedQueueV1) - 단순한 구현과 데이터 유실**

- **방식**: 생산자는 버퍼가 가득 차면 데이터를 버리고, 소비자는 버퍼가 비어 있으면 `null`을 반환받는다.
- **결과**: 이 방식은 **데이터 유실**을 야기하고, 소비자는 유효한 데이터를 얻지 못한 채 CPU 자원만 낭비하는 **비효율**을 낳는다.

##### **2단계 (V2-BoundedQueueV2) - `sleep`을 이용한 대기와 교착 상태(Deadlock)**

- **방식**: 데이터 유실을 막기 위해, `synchronized` 메서드 내에서 `while` 루프와 `sleep()`을 사용해 조건이 만족될 때까지 스레드를 대기시킨다.
- **결과**: 이는 **치명적인 교착 상태(Deadlock)를 유발**한다. 스레드가 **모니터 락(lock)을 해제하지 않은 채** `sleep()` 상태에 빠지기 때문이다. 결과적으로 락을 점유한 스레드가 잠든 동안 다른 어떤 스레드도 임계 영역에 진입할 수 없어, 시스템 전체가 멈추는 심각한 문제가 발생한다.

##### **3단계 (V3-BoundedQueueV3) - `wait()`와 `notify()`를 통한 올바른 협력**

- **방식**: `Object` 클래스가 가진 `wait()`와 `notify()`를 통해 교착 상태 문제를 해결한다.
- **핵심 원리**:
  - **`wait()`**: `synchronized` 블록 내에서 호출될 때 **현재 스레드가 가진 락을 반납하고 대기 상태로 전환**시킨다. 이것이 `sleep()`과의 결정적 차이이며, 다른 스레드가 락을 획득해 임계 영역에 진입하도록 길을 열어준다.
  - **`notify()`**: 대기 집합(Wait Set)에서 대기하는 스레드 중 임의의 하나를 깨워 락을 다시 획득할 기회를 준다.
- **동작 흐름**:
  - 생산자는 버퍼가 가득 차면 `wait()`하며 대기한다.
  - 소비자는 버퍼가 비어 있으면 `wait()`하며 대기한다.
  - 각자는 자신의 작업을 마친 후 `notify()`를 호출해 상대방을 깨워줌으로써, 데이터 손실이나 교착 상태 없이 안전하게 작업을 처리할 수 있다.

### 3. `wait()`/`notify()` 방식의 한계와 대안

`wait()`/`notify()` 방식은 올바르게 동작하지만, **하나의 대기 집합(Wait Set)** 을 공유하는 데서 오는 근본적인 한계가 존재한다.

- **임의의 스레드 통지 (Arbitrary Notification)**: `notify()`는 대기 중인 스레드 중 어떤 스레드가 깨어날지 보장하지 않는다.
- **비효율적인 깨우기 (Inefficient Wake-ups)**: 이로 인해 생산자가 다른 생산자를, 소비자가 다른 소비자를 깨우는 비효율이 발생할 수 있다. 불필요하게 깨어난 스레드는 조건을 만족하지 못해 즉시 다시 `wait()` 상태로 돌아가며 CPU 자원만 낭비한다.
- **스레드 기아 상태 (Thread Starvation)**: 최악의 경우, `notify()`가 특정 스레드를 계속해서 무시하여 해당 스레드가 영원히 실행되지 못하는 기아 상태에 빠질 수 있다.
- **`notifyAll()` 사용과 그 비용**: `notifyAll()`은 대기 중인 모든 스레드를 깨워 기아 문제를 해결하는 확실한 방법이다. 하지만 모든 스레드가 깨어나 락 경쟁을 벌이므로, 불필요한 컨텍스트 스위칭을 대량으로 유발하여 성능 저하를 감수해야 하는 단점이 있다.

> 모든 자바 객체는 각각 하나의 모니터 락(monitor lock)과 하나의 스레드 대기 집합(Wait Set)을 가진다.  
> 스레드 대기 집합이란 객체의 모니터 락을 보유한 스레드가 `wait()` 메서드를 호출하여 스스로 대기 상태로 전환되었을 때 들어가는 공간이다.  
> `notify()`를 호출하면 이 대기 집합에 있는 스레드 중 단 하나를 깨운다. 어떤 스레드를 깨울지는 JVM 구현에 따라 다르므로 예측할 수 없다.  
> 이 때문에 최악의 경우 특정 스레드가 영원히 깨어나지 못하는 **기아 상태(Starvation)** 에 빠질 수 있다.  
> 이러한 문제를 해결하기 위해 `notifyAll()`을 사용한다. `notifyAll()`은 대기 집합의 모든 스레드를 깨워 락을 얻기 위해 경쟁시킨다.  
> 깨어난 스레드들은 `while` 루프를 통해 자신이 기다리던 조건을 다시 확인하고, 조건이 충족되지 않은 스레드는 `wait()`을 호출하여 다시 대기 집합으로 돌아간다.  
> 이 방식은 기아 상태를 방지하여 프로그램의 정확성을 보장하지만, 불필요한 모든 스레드를 깨우고 락 경쟁을 시키므로 **컨텍스트 스위칭과 락 경합으로 인한 성능 저하(비효율)** 는 감수해야 한다.

---

## 9. 생산자 소비자 문제2

### 생산자-소비자 문제의 비효율과 해결 방안

생산자-소비자 모델에서 `synchronized`와 `wait()`, `notify()`를 사용할 경우, 스레드 대기 집합이 하나이기 때문에 생산자가 다른 생산자를 깨우거나 소비자가 다른 소비자를 깨우는 비효율이 발생할 수 있다.

이 문제의 핵심 해결책은 생산자 스레드와 소비자 스레드가 대기하는 공간을 분리하는 것이다. 즉, 생산자는 데이터를 생성한 후 소비자에게만 신호를 보내고, 소비자는 데이터를 소비한 후 생산자에게만 신호를 보내도록 구현해야 한다. Java 1.5부터 제공되는 `Lock` 인터페이스와 `ReentrantLock` 구현체를 사용하면 이를 해결할 수 있다.

---

### `ReentrantLock`과 `Condition`을 활용한 문제 해결

`ReentrantLock`은 `synchronized`보다 더 세밀한 제어를 가능하게 하며, `Condition` 객체를 통해 스레드 대기 공간을 직접 만들고 관리할 수 있다.

#### 1단계: `ReentrantLock`과 단일 `Condition` (V4-BoundedQueueV4)

`synchronized`를 `ReentrantLock`으로, `Object.wait()`/`notify()`를 단일 `Condition` 객체의 `await()`/`signal()`로 대체한 버전이다.

- `lock.newCondition()`: 새로운 스레드 대기 공간(`Condition`)을 생성한다.
- `condition.await()`: 현재 스레드를 대기 상태로 만들고, 획득한 락을 반납한다.
- `condition.signal()`: 대기 중인 스레드 중 하나를 깨운다.

이 방식은 구현 기술만 변경했을 뿐, 여전히 대기 공간이 하나이므로 근본적인 비효율 문제는 해결되지 않았다.

#### 2단계: 대기 공간 분리를 통한 최적화 (V5-BoundedQueueV5)

진정한 최적화는 `Lock` 객체 하나에 두 개의 `Condition` 객체를 생성하여 대기 공간을 분리하는 것이다.

- `producerCond`: 생산자 스레드 전용 대기 공간이다.
- `consumerCond`: 소비자 스레드 전용 대기 공간이다.

**작동 방식:**

- **생산자 (`put`)**: 큐가 가득 차면 `producerCond.await()`를 호출해 대기하고, 데이터 저장 후에는 `consumerCond.signal()`을 호출해 대기 중인 소비자를 깨운다.
- **소비자 (`take`)**: 큐가 비어 있으면 `consumerCond.await()`를 호출해 대기하고, 데이터 소비 후에는 `producerCond.signal()`을 호출해 대기 중인 생산자를 깨운다.

이처럼 생산자는 소비자를, 소비자는 생산자를 직접 깨우기 때문에 불필요한 스레드 각성이 사라져 매우 효율적으로 동작한다.

---

> ## **`synchronized`의 내부 동작 원리**
>
> ### **1. 락 획득 대기와 '락 대기 집합'**
>
> **정의**: '락 대기 집합'은 객체의 모니터 락(Monitor Lock)을 획득하기 위해 대기하는 스레드들을 관리하는 공간이다.
> **진입 조건**: 한 스레드가 `synchronized` 블록에 진입하려고 할 때 다른 스레드가 이미 락을 점유하고 있으면, 락을 얻지 못한 스레드는 `BLOCKED` 상태가 되어 이 집합에서 대기한다.
> **역할**: 이 집합은 락이 반납되었을 때 대기 중인 스레드 중 하나에게 락을 제공하는 역할을 한다.
>
> ---
>
> ### **2. `wait()` 대기와 '스레드 대기 집합'**
>
> **정의**: '스레드 대기 집합'은 특정 조건을 기다리기 위해 `wait()` 메소드를 호출한 스레드들을 관리하는 공간이다.
> **진입 조건**: 스레드가 **모니터 락을 획득한 상태에서** `wait()` 메소드를 호출하면, 해당 스레드는 획득했던 락을 즉시 반납하고 `WAITING` 상태로 '스레드 대기 집합'에 들어간다.
> **역할**: 이곳의 스레드들은 다른 스레드가 `notify()` 또는 `notifyAll()`을 호출해주어야만 깨어날 수 있다.
>
> ---
>
> ### **3. 두 집합의 상호작용: "2중 감옥" 모델**
>
> 스레드 대기 집합'에서 깨어난 스레드는 두 개의 대기소를 모두 거쳐야만 임계 영역 실행을 재개할 수 있다.
>
> **1단계: 각성 (`스레드 대기 집합` 탈출)**
>
> - 다른 스레드가 `notify()`를 호출하면 '스레드 대기 집합'에 있던 스레드 중 하나가 깨어나 집합을 빠져나온다.
>
> **2단계: 락 재획득 시도 및 이동 (`락 대기 집합` 진입)**
>
> - 깨어난 스레드는 즉시 코드를 실행하는 것이 아니라, 임계 영역에 재진입하기 위해 다시 모니터 락 획득을 시도해야 한다.
> - 만약 `notify()`를 호출한 스레드가 아직 락을 반납하지 않아 락을 얻을 수 없다면, 깨어난 스레드는 **'락 대기 집합'으로 이동하여 `BLOCKED` 상태로 대기한다.** 이것이 '2차 대기소'에서 '1차 대기소'로 이동하는 핵심적인 과정이다.
>
> **3단계: 최종 락 획득 (`락 대기 집합` 탈출)**
>
> - `notify()`를 호출했던 스레드가 `synchronized` 블록을 완전히 빠져나가 락을 반납하면, '락 대기 집합'에서 기다리던 스레드가 비로소 락을 획득하고 임계 영역 실행을 이어간다.
>
> ---
>
> ## **`ReentrantLock` 의 내부 동작 원리**
>
> `ReentrantLock` 역시 `synchronized`와 마찬가지로 2단계의 대기 상태가 존재한다. 하지만 스레드의 상태, 관리 주체 등에서 중요한 차이점을 보인다.
>
> ---
>
> #### **1. `synchronized`의 대기 방식 (비교 대상)**
>
> 먼저 비교를 위해 `synchronized`의 대기 방식을 요약하면 다음과 같다.
>
> - **대기 1 (락 획득 대기)**: `synchronized` 블록 진입 시 락이 없으면 `BLOCKED` 상태로 '락 대기 집합'에서 대기한다.
> - **대기 2 (`wait()` 조건 대기)**: `wait()` 호출 시 락을 반납하고 `WAITING` 상태로 '스레드 대기 집합'에서 대기한다.
>
> ---
>
> #### **2. `ReentrantLock`의 대기 방식**
>
> `ReentrantLock`은 대기 상태와 관리 주체가 `synchronized`와 다르다.
>
> - **대기 1: `lock()`을 통한 락 획득 대기**
>
>   - **관리 주체**: `ReentrantLock` 객체 내부의 '대기 큐(Wait Queue)'에서 스레드를 관리한다.
>   - **스레드 상태**: 락을 기다리는 스레드는 `BLOCKED`가 아닌 **`WAITING`** 상태가 된다. 이것이 `synchronized`와의 가장 큰 차이점 중 하나이다.
>
> - **대기 2: `await()`을 통한 조건 대기**
>   - **관리 주체**: `lock.newCondition()`을 통해 생성된 별도의 `Condition` 객체의 '스레드 대기 공간'에서 스레드를 관리한다. (객체 자체에 내장된 `synchronized`와 달리, `Condition` 객체를 필요에 따라 여러 개 만들 수 있다.)
>   - **스레드 상태**: `await()`을 호출한 스레드는 `WAITING` 상태가 된다.
>
> ---
>
> #### **3. `ReentrantLock`의 2단계 대기소 동작**
>
> `await()` 상태에서 깨어난 스레드 역시 `synchronized`와 마찬가지로 2단계에 걸쳐 실행 권한을 얻는다.
>
> 1.  `signal()` 호출로 `Condition`의 대기 공간에서 스레드가 깨어난다.
> 2.  깨어난 스레드는 즉시 실행되지 않고, `ReentrantLock`의 락을 재획득해야 한다.
> 3.  만약 락을 바로 획득하지 못하면, 해당 스레드는 `ReentrantLock`의 '대기 큐'에 들어가 **`WAITING`** 상태로 락 획득을 기다린다.
>
> 결론적으로 `signal()`로 깨어난 스레드라 할지라도, 임계 영역을 실행하기 위해서는 반드시 락을 획득하는 과정을 거쳐야 한다.
>
> ---
>
> #### **핵심 차이점 요약**
>
> | 구분               | `synchronized`                    | `ReentrantLock`                  |
> | :----------------- | :-------------------------------- | :------------------------------- |
> | **락 대기 상태**   | `BLOCKED`                         | `WAITING`                        |
> | **락 대기 관리**   | 객체 내장 '락 대기 집합'          | `ReentrantLock`의 '대기 큐'      |
> | **조건 대기 관리** | 객체 내장 단일 '스레드 대기 집합' | 별도로 생성하는 `Condition` 객체 |

---

### Java 내장 솔루션: `BlockingQueue`

직접 구현한 `BoundedQueueV5`와 같이 스레드를 제어하는 큐를 자바는 `java.util.concurrent.BlockingQueue` 인터페이스로 제공한다. `BlockingQueue`는 큐가 특정 조건에 도달했을 때 스레드 작업을 차단(Block)한다.

- **데이터 추가 차단**: 큐가 가득 차면 `put()`을 시도하는 스레드는 공간이 생길 때까지 대기한다.
- **데이터 획득 차단**: 큐가 비어 있으면 `take()`를 시도하는 스레드는 데이터가 들어올 때까지 대기한다.

대표적인 구현체인 `ArrayBlockingQueue`는 내부적으로 `ReentrantLock`과 두 개의 `Condition`(`notFull`, `notEmpty`)을 사용하여 `BoundedQueueV5`와 거의 동일한 방식으로 구현되어 있다.

#### `BlockingQueue`의 주요 메서드

`BlockingQueue`는 상황에 따라 다양한 동작을 선택할 수 있도록 여러 메서드를 제공한다.

| 동작 방식          | 데이터 추가 (큐가 꽉 찼을 때)                 | 데이터 가져오기 (큐가 비었을 때)         |
| :----------------- | :-------------------------------------------- | :--------------------------------------- |
| **예외 발생**      | `add(e)` (`IllegalStateException`)            | `remove()` (`NoSuchElementException`)    |
| **특정 값 반환**   | `offer(e)` (`false` 반환)                     | `poll()` (`null` 반환)                   |
| **무한 대기**      | `put(e)` (공간이 생길 때까지 대기)            | `take()` (데이터가 생길 때까지 대기)     |
| **시간 제한 대기** | `offer(e, time, unit)` (시간 초과 시 `false`) | `poll(time, unit)` (시간 초과 시 `null`) |

---

## 10. 동기화와 원자적 연산

### CAS(Compare-And-Swap)와 원자적 연산

#### 1. 원자적 연산의 개념과 문제점

**원자적 연산(Atomic Operation)** 이란, 다른 연산의 간섭 없이 완전히 실행되거나 전혀 실행되지 않는, 더는 나눌 수 없는 연산 단위를 의미한다. 멀티스레드 환경에서 스레드 간섭 없이 안전하게 처리되는 연산을 뜻한다.

- **원자적 연산의 예**: `i = 1` 과 같은 단순 대입 연산은 하나의 명령으로 처리되므로 원자적이다.
- **비원자적 연산의 예**: `i = i + 1` 또는 이를 축약한 `i++`는 원자적 연산이 아니다. 이 연산은 내부적으로 다음과 같이 세 단계로 나뉘어 실행된다:
  1.  변수 `i`의 현재 값을 읽는다.
  2.  읽은 값에 1을 더한다.
  3.  계산된 결과를 변수 `i`에 대입한다.

이러한 비원자적 연산은 여러 스레드가 동시에 접근할 때 **경쟁 상태(Race Condition)** 를 유발한다. 예를 들어, 두 스레드가 동시에 `i`의 값 0을 읽고 각자 1을 더한 후 `i`에 1을 대입하면, 최종 결과는 기대값인 2가 아닌 1이 되어 연산 한 번이 유실되는 문제가 발생한다.

#### 2. 비원자적 연산 문제 해결 시도

이 문제를 해결하기 위해 여러 가지 방법을 시도할 수 있다.

- **`volatile` 키워드**: `volatile`은 CPU 캐시가 아닌 메인 메모리에서 직접 값을 읽고 쓰도록 보장하여 메모리 가시성 문제를 해결한다. 하지만 연산 자체를 원자적으로 묶어주지는 않기 때문에 `i++`와 같은 비원자적 연산의 경쟁 상태 문제는 해결할 수 없다.
- **`synchronized` 키워드**: 메서드나 코드 블록에 `synchronized`를 사용하면 임계 영역(Critical Section)이 생성된다. 한 번에 하나의 스레드만 이 영역에 접근할 수 있으므로, `value++` 연산의 원자성을 보장하여 정확한 결과를 얻을 수 있다.

#### 3. `AtomicInteger`와 성능

자바는 `AtomicInteger`와 같이 멀티스레드 환경에서 원자적 연산을 안전하게 지원하는 클래스를 제공한다. `AtomicInteger`의 `incrementAndGet()` 메서드를 사용하면 `synchronized`와 동일하게 정확한 결과를 보장한다.

성능 테스트 결과, `AtomicInteger`는 `synchronized`를 사용하는 방식보다 1.5~2배가량 빠른 성능을 보인다. `AtomicInteger`는 `synchronized`와 같은 락(Lock)을 사용하지 않고도 원자성을 보장하기 때문이다.

#### 4. CAS(Compare-And-Swap) 연산의 원리

`AtomicInteger`가 락 없이 높은 성능을 내는 비결은 **CAS(Compare-And-Swap)** 연산에 있다. CAS는 락을 사용하지 않는 **락 프리(Lock-Free)** 기법이다.

- **개념**: `compareAndSet(expectedValue, newValue)` 형태로 사용된다. 현재 메모리의 값이 `expectedValue`(기대값)와 일치하는지 비교하고, 일치하면 `newValue`(새로운 값)로 교체하는 연산을 **하나의 원자적 단위**로 처리한다.
- **하드웨어 지원**: CAS는 소프트웨어가 아닌 CPU 하드웨어 차원에서 원자적으로 지원하는 특별한 명령어이다. CPU는 '값 비교'와 '값 변경' 두 과정을 중간에 다른 스레드가 개입할 수 없도록 하나의 명령으로 묶어 처리한다.
- **동작 방식**:
  - **성공**: 현재 값이 기대값과 일치하면 값을 새로운 값으로 변경하고 `true`를 반환한다.
  - **실패**: 현재 값이 기대값과 다르면(다른 스레드가 중간에 값을 변경한 경우) 값을 변경하지 않고 `false`를 반환한다.

#### 5. CAS를 이용한 락 프리(Lock-Free) 구현

CAS를 활용하면 `i++`와 같은 비원자적 연산을 락 없이 구현할 수 있다. 핵심은 **반복적인 재시도**이다.

```java
// incrementAndGet()의 CAS 기반 구현 원리
do {
    currentValue = atomicInteger.get(); // 1. 현재 값을 읽는다.
    // 2. 현재 읽은 값을 기반으로 CAS 연산 시도
    result = atomicInteger.compareAndSet(currentValue, currentValue + 1);
} while (!result); // 3. 실패하면(result=false) 성공할 때까지 루프를 반복한다.
```

여러 스레드가 동시에 값을 변경하려 할 때, 한 스레드가 먼저 성공하면 다른 스레드는 CAS 연산에 실패한다. 실패한 스레드는 `do-while` 루프를 다시 돌며 최신 값을 읽어와 성공할 때까지 재시도한다.

#### 6. CAS 방식과 락(Lock) 방식의 비교

- **락(Lock) 방식 (비관적 접근)**: "다른 스레드가 항상 방해할 것"이라 가정하고, 데이터 접근 전에 항상 락을 획득한다. 충돌은 없지만 모든 연산에 락 획득 및 해제 오버헤드가 발생한다.
- **CAS 방식 (낙관적 접근)**: "대부분 충돌이 없을 것"이라 가정하고 락 없이 바로 접근한다. 충돌이 발생하면 그때 재시도한다.

**결론**: 스레드 간 충돌이 드물게 발생하는 환경에서는 CAS 방식이 락을 획득하고 대기하는 시간이 없어 더 높은 성능을 보인다. `i++`와 같은 간단한 CPU 연산은 매우 빨라 스레드 충돌이 자주 발생하지 않으므로, 락보다는 CAS를 사용하는 것이 효과적이다.

### CAS를 이용한 락(Lock) 구현 및 장단점

#### 1. CAS를 이용한 락 구현

`synchronized`나 `Lock` 객체 없이, CAS 연산만으로 락을 구현할 수 있다.

##### 잘못된 락 구현 (`SpinLockBad`)

`volatile boolean` 변수를 플래그로 사용해 락을 구현하려는 시도는 실패한다. 그 이유는 '락 사용 여부 확인(if)'과 '락 값 변경(=)'이 원자적으로 실행되지 않기 때문이다. 두 스레드가 동시에 `lock`이 `false`인 것을 확인한 후, 연달아 `lock`을 `true`로 변경하면 두 스레드 모두 락을 획득하는 심각한 동시성 문제가 발생한다.

##### 올바른 CAS 기반 락 구현 (`SpinLock`)

이 문제는 `AtomicBoolean`의 `compareAndSet(false, true)`를 사용해 해결할 수 있다. 이 CAS 연산은 "현재 값이 `false`이면 `true`로 변경하라"는 두 가지 동작을 하나의 원자적 연산으로 묶어준다.  
한 스레드가 `compareAndSet(false, true)`를 호출해 성공하면(`true` 반환) 락을 획득하고 루프를 탈출한다. 다른 스레드가 연이어 호출하면, `lock`의 값이 이미 `true`이므로 CAS 연산은 실패하고(`false` 반환), 락을 획득할 때까지 `while` 루프를 계속 반복하며 대기한다.

#### 2. 스핀 락 (Spin Lock) 과 바쁜 대기 (Busy-Wait)

이처럼 락을 획득할 때까지 `while` 루프를 반복하며 대기하는 방식을 **스핀 락(Spin Lock)** 이라고 부른다. 스레드가 제자리에서 회전(spin)하는 것처럼 보이기 때문이다.  
이때 스레드는 `BLOCKED`나 `WAITING` 상태로 전환되어 휴식하는 것이 아니라, `RUNNABLE` 상태를 유지하며 CPU 자원을 계속 소모한다. 이를 **바쁜 대기(Busy-Wait)**라고 한다.

#### 3. 스핀 락의 단점과 사용 시나리오

스핀 락의 가장 큰 단점은 **CPU 자원 낭비**이다. 락을 보유한 스레드의 작업(임계 영역)이 길어지면, 대기하는 스레드들은 아무 작업도 하지 않으면서 CPU만 계속 소모하게 된다.  
따라서 스핀 락은 다음과 같은 매우 제한적인 경우에만 효율적이다.

- **임계 영역의 연산이 극도로 짧을 때**: 스레드를 `BLOCKED` 시켰다가 다시 깨우는 컨텍스트 스위칭 비용보다, 아주 잠깐 CPU를 사용하며 대기하는 비용이 더 저렴한 경우에 효과적이다. (예: 숫자 값 증가, 자료구조 데이터 추가 등)
- **사용하면 안 되는 경우**: 데이터베이스 조회나 외부 API 호출처럼 대기 시간이 길어질 수 있는 작업에 스핀 락을 사용하면, CPU 자원을 심각하게 낭비하는 최악의 결과를 초래할 수 있다.

#### 4. 최종 정리: CAS 방식 vs 동기화 락 방식

| 구분     | **CAS (락 프리 방식)**                                                                                     | **동기화 락 (synchronized, Lock)**                                                                 |
| :------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------- |
| **장점** | 락을 걸지 않아 스레드가 블로킹되지 않고, 충돌이 적은 환경에서 컨텍스트 스위칭 오버헤드가 없어 성능이 높다. | 충돌이 잦은 환경에서도 안정적으로 동작하며, 대기하는 스레드는 CPU를 거의 사용하지 않아 효율적이다. |
| **단점** | 충돌이 잦으면 반복적인 재시도로 인해 CPU 자원을 계속 소모하고 성능이 저하될 수 있다.                       | 락 획득/해제 과정과 스레드 상태 전환(컨텍스트 스위칭)으로 인한 오버헤드가 항상 존재한다.           |

---

## 11. 동시성 컬렉션

### 동시성 컬렉션 상세 요약

#### 1. 서론: 왜 일반 컬렉션은 멀티스레드 환경에서 위험한가?

`java.util` 패키지에 포함된 `ArrayList`, `LinkedList`, `HashMap` 등의 기본적인 컬렉션 클래스들은 여러 스레드가 동시에 접근할 때 데이터의 일관성을 보장하지 못한다. 즉, **스레드 세이프(Thread Safe)하지 않다**. 이 문제는 컬렉션의 내부 동작 방식에서 기인한다.

#### 2. 문제 심층 분석: `add()` 메서드의 비원자성

`list.add("A")`와 같은 메서드 호출은 겉보기에는 하나의 동작처럼 보이지만, 내부적으로는 여러 단계의 연산으로 구성된다. 예를 들어, 직접 구현한 `BasicList`의 `add` 메서드를 통해 이 문제를 구체적으로 살펴볼 수 있다.

```java
public void add(Object e) {
    elementData[size] = e; // 1단계: 배열에 요소 저장
    size++;                // 2단계: 크기 변수 증가
}
```

이 두 단계는 원자적으로 실행되지 않는다. 두 개의 스레드(스레드1, 스레드2)가 거의 동시에 `add()`를 호출하는 상황을 가정하면 다음과 같은 문제가 발생한다.

1.  **데이터 덮어쓰기**:

    - 두 스레드 모두 `size` 변수 값이 0인 시점에 메서드를 시작한다.
    - 스레드1이 `elementData[0] = "A"`를 실행한다.
    - 직후 스레드2가 `elementData[0] = "B"`를 실행하면서, 스레드1이 저장한 "A"를 덮어쓴다.
    - 결과적으로 배열의 0번 인덱스에는 "B"만 남게 된다.

2.  **크기(size) 값 불일치**:

    - `size++`는 실제로는 `size = size + 1`과 같은 연산으로, 이 역시 '`size` 값 읽기 → 1 더하기 → `size`에 결과 쓰기'의 3단계로 나뉜다.
    - 만약 두 스레드가 `size`가 0인 상태를 동시에 읽고, 각자 1을 더한 후, `size`에 1을 쓰는 동작을 순차적으로 수행하면 최종 `size`는 1이 된다.
    - 결과적으로, `list`에는 데이터 "B" 하나만 저장되어 있고 `size`는 2가 되는(또는 `size`마저 1이 되는) 데이터 불일치 상태에 빠진다.

이처럼 일반 컬렉션은 멀티스레드 환경에서 데이터 유실, 상태 불일치 등 예측 불가능하고 해결하기 어려운 버그를 유발한다.

#### 3. 해결 방안 1: 프록시 패턴을 이용한 안전한 동기화

가장 간단한 해결책은 `synchronized` 키워드로 메서드를 감싸 임계 영역을 만드는 것이다. 하지만 `ArrayList`를 복사해 `SyncArrayList`를 만드는 방식은 모든 컬렉션에 대해 중복 코드를 양산하므로 비효율적이다.

이때 **프록시(Proxy) 패턴**이 효과적인 대안이 된다.

- **개념**: 실제 대상 객체(원본 컬렉션)를 대신하는 '대리자' 객체를 만드는 것이다. 클라이언트는 원본이 아닌 프록시를 통해 작업을 요청한다.
- **동기화 프록시의 작동 방식**:
  1.  동기화 프록시(`SyncProxyList`)는 원본 객체(`BasicList`)와 동일한 인터페이스(`SimpleList`)를 구현한다.
  2.  프록시는 생성자를 통해 원본 객체의 참조를 전달받아 내부 필드로 가지고 있는다.
  3.  클라이언트가 프록시의 `add()` 메서드를 호출하면, 프록시는 먼저 `synchronized`를 통해 락을 획득한다.
  4.  락을 획득한 상태에서, 내부에 가지고 있던 원본 객체의 `add()` 메서드를 대신 호출(delegate)한다.
  5.  원본의 작업이 끝나면, 프록시는 락을 해제하고 결과를 클라이언트에게 반환한다.

이 방식을 통해 원본 컬렉션의 코드를 전혀 수정하지 않고도, 필요할 때만 동기화 기능을 '덧씌울' 수 있어 유연하고 효율적인 구조를 만들 수 있다.

#### 4. 자바의 기본 동기화 컬렉션: `Collections.synchronizedXxx()`

자바는 이러한 프록시 방식을 `Collections.synchronizedList()`, `synchronizedMap()` 등의 유틸리티 메서드로 제공한다. 이 메서드들은 원본 컬렉션을 인자로 받아, 모든 메서드가 `synchronized` 처리된 프록시 래퍼(wrapper) 객체를 반환한다.

하지만 이 방식은 **단순하고 무식하게 모든 메서드를 동기화**하기 때문에 다음과 같은 명확한 한계를 가진다.

- **성능 저하**: 불필요한 경우에도 모든 메서드 호출에 동기화 오버헤드가 발생한다.
- **넓은 잠금 범위**: 컬렉션 객체 전체에 락이 걸리므로, 한 스레드가 읽기 작업을 하는 동안 다른 스레드는 쓰기는 물론 읽기 작업조차 할 수 없다. 이는 병렬 처리의 이점을 크게 해치고 **잠금 경합(Lock Contention)** 을 증가시킨다.
- **정교한 제어 불가**: 특정 조건에서만 잠그는 등의 세밀한 동기화 전략을 구사할 수 없다.

#### 5. 궁극적인 해결책: `java.util.concurrent` 패키지의 동시성 컬렉션

`synchronized` 방식의 한계를 극복하기 위해, 자바는 멀티스레드 환경에 특화된 고성능 **동시성 컬렉션**들을 `java.util.concurrent` 패키지를 통해 제공한다.

- **고성능의 비결**: 이 컬렉션들은 단순 `synchronized`가 아닌, `Lock`, **CAS(Compare-And-Swap)**, **부분 잠금(Segment Lock)** 등 훨씬 정교하고 최적화된 동기화 기법들을 내부적으로 사용한다. 이를 통해 잠금의 범위를 최소화하고 동시성을 극대화하여 높은 처리량을 달성한다.

동시성 컬렉션의 종류

- `List`
  - `CopyOnWriteArrayList` `ArrayList` 의 대안
- `Set`
  - `CopyOnWriteArraySet` `HashSet` 의 대안
  - `ConcurrentSkipListSet` `TreeSet` 의 대안(정렬된 순서 유지, `Comparator` 사용 가능)
- `Map`
  - `ConcurrentHashMap` : `HashMap` 의 대안
  - `ConcurrentSkipListMap` : `TreeMap` 의 대안(정렬된 순서 유지, `Comparator` 사용 가능)
- `Queue`
  - `ConcurrentLinkedQueue` : 동시성 큐, 비 차단(non-blocking) 큐이다.
- `Deque`
  - `ConcurrentLinkedDeque` : 동시성 데크, 비 차단(non-blocking) 큐이다.

> 참고로 `LinkedHashSet` , `LinkedHashMap` 처럼 입력 순서를 유지하는 동시에 멀티스레드 환경에서 사용할 수 있는 `Set` , `Map` 구현체는 제공하지 않는다.  
> 필요하다면 `Collections.synchronizedXxx()` 를 사용해야 한다.

- `BlockingQueue`
  - `ArrayBlockingQueue`
    - 크기가 고정된 블로킹 큐
    - 공정(fair) 모드를 사용할 수 있다. 공정(fair) 모드를 사용하면 성능이 저하될 수 있다.
- `LinkedBlockingQueue`
  - 크기가 무한하거나 고정된 블로킹 큐
- `PriorityBlockingQueue`
  - 우선순위가 높은 요소를 먼저 처리하는 블로킹 큐
- `SynchronousQueue`
  - 데이터를 저장하지 않는 블로킹 큐로, 생산자가 데이터를 추가하면 소비자가 그 데이터를 받을 때까지 대기한다. 생산자-소비자 간의 직접적인 핸드오프(hand-off) 메커니즘을 제공한다. 쉽게 이야기해서 중간에 큐 없이 생산자, 소비자가 직접 거래한다.
- `DelayQueue`
  - 지연된 요소를 처리하는 블로킹 큐로, 각 요소는 지정된 지연 시간이 지난 후에야 소비될 수 있다. 일정 시간이 지난 후 작업을 처리해야 하는 스케줄링 작업에 사용된다.

## 12. 스레드 풀과 Executor 프레임워크1

### 스레드 풀과 Executor 프레임워크 상세 요약

#### 1. 스레드를 직접 생성하여 사용할 때의 문제점

실무에서 스레드를 직접 `new Thread()`로 생성해 사용하면 크게 3가지 문제가 발생한다.

**1) 스레드 생성 비용으로 인한 성능 문제**
스레드 생성은 단순히 자바 객체를 만드는 것과 달리 매우 무거운 작업이다.

- **메모리 할당**: 각 스레드는 자신만의 호출 스택(Call Stack)을 위해 1MB 이상의 큰 메모리 공간을 할당받는다.
- **운영체제 자원 사용**: 스레드 생성은 운영체제(OS) 커널 수준에서 시스템 콜(System Call)을 통해 이루어지므로 CPU와 메모리 자원을 많이 소모한다.
- **OS 스케줄러 오버헤드**: 새로운 스레드가 생성되면 OS 스케줄러는 이 스레드를 관리 대상에 포함시켜야 하므로 추가적인 오버헤드가 발생한다.

이러한 이유로, 작업 요청이 있을 때마다 스레드를 생성하고 폐기하는 방식은 심각한 성능 저하를 유발한다. 때로는 실제 작업 시간보다 스레드를 생성하는 데 더 많은 시간이 걸릴 수도 있다. 이 문제의 해결책은 생성된 스레드를 **재사용**하는 것이다.

**2) 스레드 관리 문제**
서버의 자원은 한정적이므로 스레드를 무한정 생성할 수 없다. 사용자의 요청이 폭주하여 수많은 스레드가 동시에 생성되면 시스템은 자원 고갈로 다운될 수 있다. 따라서 시스템이 감당할 수 있는 **최대 스레드 수를 제한하고 관리**할 필요가 있다. 또한, 애플리케이션을 안전하게 종료하기 위해 실행 중인 모든 스레드의 작업을 마무리하거나 중단시키는 등의 제어 로직도 필요하지만, 이를 직접 구현하는 것은 매우 복잡하다.

**3) `Runnable` 인터페이스의 불편함**
`Runnable` 인터페이스의 `run()` 메서드는 두 가지 큰 불편함이 있다.

- **반환 값이 없음**: `run()` 메서드의 반환 타입은 `void`이므로, 스레드의 작업 결과를 직접 받을 수 없다. 결과를 얻으려면 별도의 멤버 변수에 결과를 저장하고, `join()`을 사용해 스레드가 종료될 때까지 기다린 후 해당 변수를 읽어오는 복잡한 과정이 필요하다.
- **체크 예외(Checked Exception) 처리 불가**: `run()` 메서드는 체크 예외를 던질 수 없도록 선언되어 있어, 예외 처리가 메서드 내부로 강제된다.

#### 2. 해결책: 스레드 풀(Thread Pool)

앞서 제기된 '성능'과 '관리' 문제를 해결하기 위한 핵심 개념이 바로 **스레드 풀(Thread Pool)** 이다.

- **동작 원리**:
  1.  필요한 만큼의 스레드를 미리 생성하여 '풀(Pool)'에 보관해둔다.
  2.  작업 요청이 오면, 새로 스레드를 생성하는 대신 풀에서 쉬고 있는 스레드를 하나 꺼내 작업을 할당한다.
  3.  작업을 마친 스레드는 종료되지 않고 다시 풀로 반납되어 다음 작업을 기다린다.
- **장점**:
  - **성능 향상**: 스레드를 재사용하므로 비싼 생성 비용이 발생하지 않는다.
  - **자원 관리**: 미리 정해진 개수만큼만 스레드를 운영하므로 자원 고갈을 방지한다.

#### 3. Executor 프레임워크 소개

이러한 스레드 풀 개념을 포함하여, 앞서 언급된 3가지 문제를 모두 해결해주는 표준 기술이 바로 자바의 **Executor 프레임워크**이다. 이 프레임워크는 스레드의 생성과 관리, 작업 실행을 개발자 대신 처리해주어 멀티스레딩 프로그래밍을 매우 편리하게 만들어준다.

- **주요 인터페이스**:
  - `Executor`: `void execute(Runnable command)` 메서드 하나만 가진 가장 기본적인 인터페이스이다.
  - `ExecutorService`: `Executor`를 확장하여 작업의 제출, 제어, 종료 등 훨씬 다양한 기능을 제공한다. 실무에서는 대부분 이 인터페이스를 사용한다.
- **핵심 구현체**: `ThreadPoolExecutor`는 `ExecutorService`의 대표적인 구현체이다.

#### 4. `ThreadPoolExecutor`의 구조와 동작 원리

`ThreadPoolExecutor`는 크게 두 가지 요소로 구성된다.

1.  **스레드 풀**: 스레드를 생성하고 관리하며 재사용한다.
2.  **작업 큐 (`BlockingQueue`)**: 스레드가 처리해야 할 작업(`Runnable`)들을 보관한다.

이 구조는 **생산자-소비자 패턴**으로 동작한다.

- **생산자**: `main` 스레드 등 외부에서 `es.execute(작업)`를 호출하여 작업 큐에 작업을 넣는다.
- **소비자**: 스레드 풀에 있는 스레드들이 큐에서 작업을 꺼내 처리한다.

**실행 흐름**:

1.  `ThreadPoolExecutor`가 처음 생성될 때는 스레드가 없다.
2.  첫 작업이 `execute()`를 통해 제출되면, `corePoolSize`(핵심 스레드 수)에 도달할 때까지 새 스레드를 생성하여 풀에 추가한다.
3.  생성된 스레드들은 작업 큐에서 작업을 가져와 실행한다.
4.  작업이 끝나면 스레드는 풀에 반납되어 대기 상태로 다음 작업을 기다린다. `corePoolSize`를 넘어서는 추가 작업은 큐에서 대기한다.
5.  `main` 스레드는 `execute()` 호출 후 대기하지 않고(Non-Blocking) 즉시 다음 코드를 진행한다.
6.  모든 작업이 끝나고 `es.close()`가 호출되면 스레드 풀이 종료되고 내부 스레드들도 정리된다.

#### 5. `Runnable` 인터페이스의 한계 예시

결과 값을 반환하지 못하는 `Runnable`의 불편함을 코드로 확인하면 다음과 같다.

```java
// 결과를 저장할 멤버 변수
static class MyRunnable implements Runnable {
    int value; // 결과를 여기에 저장
    public void run() {
        // ... 작업 수행 후
        value = new Random().nextInt(10);
    }
}

// 결과를 얻는 과정
MyRunnable task = new MyRunnable();
Thread thread = new Thread(task);
thread.start();
thread.join(); // 스레드가 끝날 때까지 메인 스레드 대기 (Blocking)
int result = task.value; // 대기 후 멤버 변수에서 결과 조회
```

이처럼 별도의 스레드에서 수행된 작업의 결과를 얻는 과정이 매우 번거롭고 복잡하다. Executor 프레임워크는 이러한 문제를 해결하기 위해 `Callable`과 `Future`라는 새로운 개념을 도입했다.
